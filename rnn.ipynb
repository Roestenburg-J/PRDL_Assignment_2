{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NTjtRYkxL447"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLJacqmIQHq3",
        "outputId": "c39fec2f-d9ed-45e6-cf0c-319f9d138161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5ltmaALlL449"
      },
      "outputs": [],
      "source": [
        "def getdatasetname(file_name_with_dir):\n",
        "    filename_without_dir = file_name_with_dir.split(\"/\")[-1]\n",
        "    temp = filename_without_dir.split(\"_\")[:-1]\n",
        "    datasetname = \"_\".join(temp)\n",
        "    return datasetname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rk_y7Ak6L449"
      },
      "outputs": [],
      "source": [
        "def get_label(filename):\n",
        "    if \"rest\" in filename:\n",
        "        label = 0\n",
        "    elif \"math\" in filename:\n",
        "        label = 1\n",
        "    elif \"memory\" in filename:\n",
        "        label = 2\n",
        "    elif \"motor\" in filename:\n",
        "        label = 3\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CqLPp7xKL44_"
      },
      "outputs": [],
      "source": [
        "def get_all_matrices(dir_path):\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith(\".h5\"):\n",
        "            filename_path = dir_path + filename\n",
        "            with h5py.File(filename_path, \"r\") as f:\n",
        "                dataset_name = getdatasetname(filename_path)\n",
        "                label = get_label(filename)\n",
        "                matrix = f.get(dataset_name)[()]\n",
        "                dataset.append(matrix)\n",
        "                labels.append(label)\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MJF2BFx4NAS8"
      },
      "outputs": [],
      "source": [
        "def get_all_matrices(dir_path):\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith(\".h5\"):\n",
        "            filename_path = dir_path + filename\n",
        "            with h5py.File(filename_path, \"r\") as f:\n",
        "                dataset_name = getdatasetname(filename_path)\n",
        "                label = get_label(filename)\n",
        "                matrix = f.get(dataset_name)[()]\n",
        "                dataset.append(matrix)\n",
        "                labels.append(label)\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x0KQT9KkL45A"
      },
      "outputs": [],
      "source": [
        "def scale(matrix):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler.fit(matrix)\n",
        "    scaled_data = scaler.transform(matrix)\n",
        "    return scaled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UbSawgmiL45A"
      },
      "outputs": [],
      "source": [
        "def downsample(dataset, frequency):\n",
        "    downsampled_dataset = []\n",
        "\n",
        "    for i in range(0, dataset.shape[1], 2034):\n",
        "        second = dataset[:, i : i + 2034]\n",
        "        subsample = []\n",
        "\n",
        "        for j in range(0, 2034, int(2034 / frequency)):\n",
        "            if j < second.shape[1]:\n",
        "                measurement = second[:, j]\n",
        "                subsample.append(measurement)\n",
        "\n",
        "        downsampled_dataset.extend(subsample)\n",
        "\n",
        "    return np.array(downsampled_dataset).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW2JCa84L45B"
      },
      "source": [
        "### Data Pipeline\n",
        "\n",
        "1. Get dataset\n",
        "2. Downsample data\n",
        "3. Scale Data\n",
        "4. Train Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYd4BFYML45D"
      },
      "source": [
        "Model setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-L0I5MdL45E",
        "outputId": "dca14458-a292-486a-ee93-0eacd90dc6a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rup5-IlsMh3E"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "\n",
        "        tf.keras.layers.Dense(\n",
        "            128, activation=\"relu\"\n",
        "        ),  # The layer has 128 dense neurons using relu for activation\n",
        "\n",
        "        # tf.keras.layers.Dense(4, activation='relu'), # The layer has 128 dense neurons using relu for activation\n",
        "\n",
        "        tf.keras.layers.Dense(\n",
        "            128, activation=\"relu\"\n",
        "        ),  # The layer has 128 dense neurons using relu for activation\n",
        "\n",
        "        tf.keras.layers.Dense(\n",
        "            4\n",
        "        ),  # The final layer has 4 neurons, each representing a class for the action being done\n",
        "\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ok4qL_jsNbao"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2rMXtOzPMSu"
      },
      "source": [
        "Model training pseudo:\n",
        "\n",
        "```\n",
        "For each file in the folder:\n",
        "    Get action label from filename\n",
        "    Get matrix\n",
        "    Downsample\n",
        "    Scale\n",
        "    Train Model\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yEGWxdFlPdpj"
      },
      "outputs": [],
      "source": [
        "intra_train_path = \"your path here\"\n",
        "\n",
        "intra_test_path = \"your path here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HFED5aQ2Q4S2"
      },
      "outputs": [],
      "source": [
        "# def train_model(dir_path):\n",
        "#     dataset = []\n",
        "#     labels = []\n",
        "#     for filename in os.listdir(dir_path):\n",
        "#         if filename.endswith(\".h5\"):\n",
        "#             filename_path = dir_path + filename\n",
        "#             with h5py.File(filename_path, \"r\") as f:\n",
        "#                 dataset_name = getdatasetname(filename_path)\n",
        "#                 label = get_label(filename)\n",
        "#                 matrix = f.get(dataset_name)[()]\n",
        "\n",
        "#                 train_meg = downsample(matrix, 113)\n",
        "#                 train_meg = scale(train_meg)\n",
        "#                 train_meg = np.array(train_meg.flatten())\n",
        "\n",
        "#                 train_label = label\n",
        "\n",
        "#                 model.fit(train_meg, train_label, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "N6LJwavfYyf7"
      },
      "outputs": [],
      "source": [
        "def load_data(dir_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith(\".h5\"):\n",
        "            filename_path = os.path.join(dir_path, filename)\n",
        "            with h5py.File(filename_path, \"r\") as f:\n",
        "                dataset_name = getdatasetname(filename_path)\n",
        "                label = get_label(filename)\n",
        "                matrix = f.get(dataset_name)[()]\n",
        "\n",
        "                train_meg = downsample(matrix, 113)\n",
        "                train_meg = scale(train_meg)\n",
        "                flattened_meg = np.array(train_meg.flatten())\n",
        "\n",
        "                data.append(flattened_meg)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oaAZ7fUSYzf4"
      },
      "outputs": [],
      "source": [
        "def train_model(dir_path, model):\n",
        "    train_data, train_labels = load_data(dir_path)\n",
        "\n",
        "    model.fit(train_data, train_labels, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "j9as6J01ZYVt"
      },
      "outputs": [],
      "source": [
        "def load_test_data(dir_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith(\".h5\"):\n",
        "            filename_path = os.path.join(dir_path, filename)\n",
        "            with h5py.File(filename_path, \"r\") as f:\n",
        "                dataset_name = getdatasetname(filename_path)\n",
        "                label = get_label(filename)\n",
        "                matrix = f.get(dataset_name)[()]\n",
        "\n",
        "                matrix = downsample(matrix, 113)\n",
        "                matrix = scale(matrix)\n",
        "                matrix = np.array(matrix.flatten())\n",
        "\n",
        "                data.append(matrix)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AAgk0CTaZZAa"
      },
      "outputs": [],
      "source": [
        "def test_model(dir_path, model):\n",
        "    test_data, test_labels = load_test_data(dir_path)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
        "\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oac6rFtHSQdu"
      },
      "outputs": [],
      "source": [
        "# def test_model(dir_path):\n",
        "#     dataset = []\n",
        "#     labels = []\n",
        "#     for filename in os.listdir(dir_path):\n",
        "#         if filename.endswith(\".h5\"):\n",
        "#             filename_path = dir_path + filename\n",
        "#             with h5py.File(filename_path, \"r\") as f:\n",
        "#                 dataset_name = getdatasetname(filename_path)\n",
        "#                 label = get_label(filename)\n",
        "#                 matrix = f.get(dataset_name)[()]\n",
        "\n",
        "#                 matrix = downsample(matrix, 113)\n",
        "#                 matrix = scale(matrix)\n",
        "\n",
        "#                 dataset.append(matrix)\n",
        "#                 labels.append(label)\n",
        "\n",
        "\n",
        "#     datasetX = np.stack(dataset)\n",
        "#     test_loss, test_acc = model.evaluate(datasetX,  labels, verbose=2)\n",
        "\n",
        "#     return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdCUhc98SEVx",
        "outputId": "372136ee-d0f3-41e5-d120-db5a50bf0c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.6251 - accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 198.6624 - accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 489.7109 - accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 325.7228 - accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 219.5514 - accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 51.2000 - accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 133.7745 - accuracy: 0.2500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 172.3834 - accuracy: 0.2500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 166.8443 - accuracy: 0.3438\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 240.3233 - accuracy: 0.2500\n"
          ]
        }
      ],
      "source": [
        "train_model(intra_train_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gM8GXJeTlxx",
        "outputId": "db17792a-fff6-4510-c422-9603695b0547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: 201.1091 - accuracy: 0.2500 - 214ms/epoch - 214ms/step\n",
            "\n",
            "Test accuracy: 0.25\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = test_model(intra_test_path, model)\n",
        "\n",
        "print(\"\\nTest accuracy:\", test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
